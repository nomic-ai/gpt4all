[
  {
    "order": "a",
    "md5sum": "c87ad09e1e4c8f9c35a5fcef52b6f1c9",
    "name": "Llama 3 8B Instruct",
    "filename": "Meta-Llama-3-8B-Instruct.Q4_0.gguf",
    "filesize": "4661724384",
    "requires": "2.7.1",
    "ramrequired": "8",
    "parameters": "8 billion",
    "quant": "q4_0",
    "type": "LLaMA3",
    "description": "<ul><li>Fast responses</li><li>Chat based model</li><li>Accepts system prompts in Llama 3 format</li><li>Trained by Meta</li><li>License: <a href=\"https://llama.meta.com/llama3/license/\">Meta Llama 3 Community License</a></li></ul>",
    "url": "https://gpt4all.io/models/gguf/Meta-Llama-3-8B-Instruct.Q4_0.gguf",
    "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2<|eot_id|>",
    "systemPrompt": ""
  },
  {
    "order": "b",
    "md5sum": "27b44e8ae1817525164ddf4f8dae8af4",
    "name": "Llama 3.2 3B Instruct",
    "filename": "Llama-3.2-3B-Instruct-Q4_0.gguf",
    "filesize": "1921909280",
    "requires": "3.4.0",
    "ramrequired": "4",
    "parameters": "3 billion",
    "quant": "q4_0",
    "type": "LLaMA3",
    "description": "<ul><li>Fast responses</li><li>Instruct model</li><li>Multilingual dialogue use</li><li>Agentic system capable</li><li>Trained by Meta</li><li>License: <a href=\"https://llama.meta.com/llama3_2/license/\">Meta Llama 3.2 Community License</a></li></ul>",
    "url": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_0.gguf",
    "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2",
    "systemPrompt": "<|start_header_id|>system<|end_header_id|>\nCutting Knowledge Date: December 2023\n\nYou are a helpful assistant.<|eot_id|>"
  },
  {
    "order": "c",
    "md5sum": "48ff0243978606fdba19d899b77802fc",
    "name": "Llama 3.2 1B Instruct",
    "filename": "Llama-3.2-1B-Instruct-Q4_0.gguf",
    "filesize": "773025920",
    "requires": "3.4.0",
    "ramrequired": "2",
    "parameters": "1 billion",
    "quant": "q4_0",
    "type": "LLaMA3",
    "description": "<ul><li>Fast responses</li><li>Instruct model</li><li>Multilingual dialogue use</li><li>Agentic system capable</li><li>Trained by Meta</li><li>License: <a href=\"https://llama.meta.com/llama3_2/license/\">Meta Llama 3.2 Community License</a></li></ul>",
    "url": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_0.gguf",
    "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2",
    "systemPrompt": "<|start_header_id|>system<|end_header_id|>\nCutting Knowledge Date: December 2023\n\nYou are a helpful assistant.<|eot_id|>"
  },
  {
    "order": "d",
    "md5sum": "a5f6b4eabd3992da4d7fb7f020f921eb",
    "name": "Nous Hermes 2 Mistral DPO",
    "filename": "Nous-Hermes-2-Mistral-7B-DPO.Q4_0.gguf",
    "filesize": "4108928000",
    "requires": "2.7.1",
    "ramrequired": "8",
    "parameters": "7 billion",
    "quant": "q4_0",
    "type": "Mistral",
    "description": "<strong>Good overall fast chat model</strong><br><ul><li>Fast responses</li><li>Chat based model</li><li>Accepts system prompts in ChatML format</li><li>Trained by Mistral AI<li>Finetuned by Nous Research on the OpenHermes-2.5 dataset<li>Licensed for commercial use</ul>",
    "url": "https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO-GGUF/resolve/main/Nous-Hermes-2-Mistral-7B-DPO.Q4_0.gguf",
    "promptTemplate": "<|im_start|>user\n%1<|im_end|>\n<|im_start|>assistant\n%2<|im_end|>\n",
    "systemPrompt": ""
  },
  {
    "order": "e",
    "md5sum": "97463be739b50525df56d33b26b00852",
    "name": "Mistral Instruct",
    "filename": "mistral-7b-instruct-v0.1.Q4_0.gguf",
    "filesize": "4108916384",
    "requires": "2.5.0",
    "ramrequired": "8",
    "parameters": "7 billion",
    "quant": "q4_0",
    "type": "Mistral",
    "systemPrompt": "",
    "description": "<strong>Strong overall fast instruction following model</strong><br><ul><li>Fast responses</li><li>Trained by Mistral AI<li>Uncensored</li><li>Licensed for commercial use</li></ul>",
    "url": "https://gpt4all.io/models/gguf/mistral-7b-instruct-v0.1.Q4_0.gguf",
    "promptTemplate": "[INST] %1 [/INST]"
  },
  {
    "order": "f",
    "md5sum": "8a9c75bcd8a66b7693f158ec96924eeb",
    "name": "Llama 3.1 8B Instruct 128k",
    "filename": "Meta-Llama-3.1-8B-Instruct-128k-Q4_0.gguf",
    "filesize": "4661212096",
    "requires": "3.1.1",
    "ramrequired": "8",
    "parameters": "8 billion",
    "quant": "q4_0",
    "type": "LLaMA3",
    "description": "<ul><li><strong>For advanced users only. Not recommended for use on Windows or Linux without selecting CUDA due to speed issues.</strong></li><li>Fast responses</li><li>Chat based model</li><li>Large context size of 128k</li><li>Accepts agentic system prompts in Llama 3.1 format</li><li>Trained by Meta</li><li>License: <a href=\"https://llama.meta.com/llama3_1/license/\">Meta Llama 3.1 Community License</a></li></ul>",
    "url": "https://huggingface.co/GPT4All-Community/Meta-Llama-3.1-8B-Instruct-128k/resolve/main/Meta-Llama-3.1-8B-Instruct-128k-Q4_0.gguf",
    "promptTemplate": "<|start_header_id|>user<|end_header_id|>\n\n%1<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n%2",
    "systemPrompt": "<|start_header_id|>system<|end_header_id|>\nCutting Knowledge Date: December 2023\n\nYou are a helpful assistant.<|eot_id|>"
  },
  {
    "order": "g",
    "md5sum": "f692417a22405d80573ac10cb0cd6c6a",
    "name": "Mistral OpenOrca",
    "filename": "mistral-7b-openorca.gguf2.Q4_0.gguf",
    "filesize": "4108928128",
    "requires": "2.7.1",
    "ramrequired": "8",
    "parameters": "7 billion",
    "quant": "q4_0",
    "type": "Mistral",
    "description": "<strong>Strong overall fast chat model</strong><br><ul><li>Fast responses</li><li>Chat based model</li><li>Trained by Mistral AI<li>Finetuned on OpenOrca dataset curated via <a href=\"https://atlas.nomic.ai/\">Nomic Atlas</a><li>Licensed for commercial use</ul>",
    "url": "https://gpt4all.io/models/gguf/mistral-7b-openorca.gguf2.Q4_0.gguf",
    "promptTemplate": "<|im_start|>user\n%1<|im_end|>\n<|im_start|>assistant\n%2<|im_end|>\n",
    "systemPrompt": "<|im_start|>system\nYou are MistralOrca, a large language model trained by Alignment Lab AI.\n<|im_end|>\n"
  },
  {
    "order": "h",
    "md5sum": "c4c78adf744d6a20f05c8751e3961b84",
    "name": "GPT4All Falcon",
    "filename": "gpt4all-falcon-newbpe-q4_0.gguf",
    "filesize": "4210994112",
    "requires": "2.6.0",
    "ramrequired": "8",
    "parameters": "7 billion",
    "quant": "q4_0",
    "type": "Falcon",
    "systemPrompt": "",
    "description": "<strong>Very fast model with good quality</strong><br><ul><li>Fastest responses</li><li>Instruction based</li><li>Trained by TII<li>Finetuned by Nomic AI<li>Licensed for commercial use</ul>",
    "url": "https://gpt4all.io/models/gguf/gpt4all-falcon-newbpe-q4_0.gguf",
    "promptTemplate": "### Instruction:\n%1\n\n### Response:\n"
  },
  {
    "order": "i",
    "md5sum": "00c8593ba57f5240f59662367b3ed4a5",
    "name": "Orca 2 (Medium)",
    "filename": "orca-2-7b.Q4_0.gguf",
    "filesize": "3825824192",
    "requires": "2.5.2",
    "ramrequired": "8",
    "parameters": "7 billion",
    "quant": "q4_0",
    "type": "LLaMA2",
    "systemPrompt": "",
    "description": "<ul><li>Instruction based<li>Trained by Microsoft<li>Cannot be used commercially</ul>",
    "url": "https://gpt4all.io/models/gguf/orca-2-7b.Q4_0.gguf"
  },
  {
    "order": "j",
    "md5sum": "3c0d63c4689b9af7baa82469a6f51a19",
    "name": "Orca 2 (Full)",
    "filename": "orca-2-13b.Q4_0.gguf",
    "filesize": "7365856064",
    "requires": "2.5.2",
    "ramrequired": "16",
    "parameters": "13 billion",
    "quant": "q4_0",
    "type": "LLaMA2",
    "systemPrompt": "",
    "description": "<ul><li>Instruction based<li>Trained by Microsoft<li>Cannot be used commercially</ul>",
    "url": "https://gpt4all.io/models/gguf/orca-2-13b.Q4_0.gguf"
  },
  {
    "order": "k",
    "md5sum": "5aff90007499bce5c64b1c0760c0b186",
    "name": "Wizard v1.2",
    "filename": "wizardlm-13b-v1.2.Q4_0.gguf",
    "filesize": "7365834624",
    "requires": "2.5.0",
    "ramrequired": "16",
    "parameters": "13 billion",
    "quant": "q4_0",
    "type": "LLaMA2",
    "systemPrompt": "",
    "description": "<strong>Strong overall larger model</strong><br><ul><li>Instruction based<li>Gives very long responses<li>Finetuned with only 1k of high-quality data<li>Trained by Microsoft and Peking University<li>Cannot be used commercially</ul>",
    "url": "https://gpt4all.io/models/gguf/wizardlm-13b-v1.2.Q4_0.gguf"
  },
  {
    "order": "l",
    "md5sum": "31b47b4e8c1816b62684ac3ca373f9e1",
    "name": "Ghost 7B v0.9.1",
    "filename": "ghost-7b-v0.9.1-Q4_0.gguf",
    "filesize": "4108916960",
    "requires": "2.7.1",
    "ramrequired": "8",
    "parameters": "7 billion",
    "quant": "q4_0",
    "type": "Mistral",
    "description": "<strong>Ghost 7B v0.9.1</strong> fast, powerful and smooth for Vietnamese and English languages.",
    "url": "https://huggingface.co/lamhieu/ghost-7b-v0.9.1-gguf/resolve/main/ghost-7b-v0.9.1-Q4_0.gguf",
    "promptTemplate": "<|user|>\n%1</s>\n<|assistant|>\n%2</s>\n",
    "systemPrompt": "<|system|>\nYou are Ghost created by Lam Hieu. You are a helpful and knowledgeable assistant. You like to help and always give honest information, in its original language. In communication, you are always respectful, equal and promote positive behavior.\n</s>"
  },
  {
    "order": "m",
    "md5sum": "3d12810391d04d1153b692626c0c6e16",
    "name": "Hermes",
    "filename": "nous-hermes-llama2-13b.Q4_0.gguf",
    "filesize": "7366062080",
    "requires": "2.5.0",
    "ramrequired": "16",
    "parameters": "13 billion",
    "quant": "q4_0",
    "type": "LLaMA2",
    "systemPrompt": "",
    "description": "<strong>Extremely good model</strong><br><ul><li>Instruction based<li>Gives long responses<li>Curated with 300,000 uncensored instructions<li>Trained by Nous Research<li>Cannot be used commercially</ul>",
    "url": "https://gpt4all.io/models/gguf/nous-hermes-llama2-13b.Q4_0.gguf",
    "promptTemplate": "### Instruction:\n%1\n\n### Response:\n"
  },
  {
    "order": "n",
    "md5sum": "40388eb2f8d16bb5d08c96fdfaac6b2c",
    "name": "Snoozy",
    "filename": "gpt4all-13b-snoozy-q4_0.gguf",
    "filesize": "7365834624",
    "requires": "2.5.0",
    "ramrequired": "16",
    "parameters": "13 billion",
    "quant": "q4_0",
    "type": "LLaMA",
    "systemPrompt": "",
    "description": "<strong>Very good overall model</strong><br><ul><li>Instruction based<li>Based on the same dataset as Groovy<li>Slower than Groovy, with higher quality responses<li>Trained by Nomic AI<li>Cannot be used commercially</ul>",
    "url": "https://gpt4all.io/models/gguf/gpt4all-13b-snoozy-q4_0.gguf"
  },
  {
    "order": "o",
    "md5sum": "15dcb4d7ea6de322756449c11a0b7545",
    "name": "MPT Chat",
    "filename": "mpt-7b-chat-newbpe-q4_0.gguf",
    "filesize": "3912373472",
    "requires": "2.7.1",
    "removedIn": "2.7.3",
    "ramrequired": "8",
    "parameters": "7 billion",
    "quant": "q4_0",
    "type": "MPT",
    "description": "<strong>Good model with novel architecture</strong><br><ul><li>Fast responses<li>Chat based<li>Trained by Mosaic ML<li>Cannot be used commercially</ul>",
    "url": "https://gpt4all.io/models/gguf/mpt-7b-chat-newbpe-q4_0.gguf",
    "promptTemplate": "<|im_start|>user\n%1<|im_end|>\n<|im_start|>assistant\n%2<|im_end|>\n",
    "systemPrompt": "<|im_start|>system\n- You are a helpful assistant chatbot trained by MosaicML.\n- You answer questions.\n- You are excited to be able to help the user, but will refuse to do anything that could be considered harmful to the user.\n- You are more than just an information source, you are also able to write poetry, short stories, and make jokes.<|im_end|>\n"
  },
  {
    "order": "p",
    "md5sum": "ab5d8e8a2f79365ea803c1f1d0aa749d",
    "name": "MPT Chat",
    "filename": "mpt-7b-chat.gguf4.Q4_0.gguf",
    "filesize": "3796178112",
    "requires": "2.7.3",
    "ramrequired": "8",
    "parameters": "7 billion",
    "quant": "q4_0",
    "type": "MPT",
    "description": "<strong>Good model with novel architecture</strong><br><ul><li>Fast responses<li>Chat based<li>Trained by Mosaic ML<li>Cannot be used commercially</ul>",
    "url": "https://gpt4all.io/models/gguf/mpt-7b-chat.gguf4.Q4_0.gguf",
    "promptTemplate": "<|im_start|>user\n%1<|im_end|>\n<|im_start|>assistant\n%2<|im_end|>\n",
    "systemPrompt": "<|im_start|>system\n- You are a helpful assistant chatbot trained by MosaicML.\n- You answer questions.\n- You are excited to be able to help the user, but will refuse to do anything that could be considered harmful to the user.\n- You are more than just an information source, you are also able to write poetry, short stories, and make jokes.<|im_end|>\n"
  },
  {
    "order": "q",
    "md5sum": "f8347badde9bfc2efbe89124d78ddaf5",
    "name": "Phi-3 Mini Instruct",
    "filename": "Phi-3-mini-4k-instruct.Q4_0.gguf",
    "filesize": "2176181568",
    "requires": "2.7.1",
    "ramrequired": "4",
    "parameters": "4 billion",
    "quant": "q4_0",
    "type": "Phi-3",
    "description": "<ul><li>Very fast responses</li><li>Chat based model</li><li>Accepts system prompts in Phi-3 format</li><li>Trained by Microsoft</li><li>License: <a href=\"https://opensource.org/license/mit\">MIT</a></li><li>No restrictions on commercial use</li></ul>",
    "url": "https://gpt4all.io/models/gguf/Phi-3-mini-4k-instruct.Q4_0.gguf",
    "promptTemplate": "<|user|>\n%1<|end|>\n<|assistant|>\n%2<|end|>\n",
    "systemPrompt": ""
  },
  {
    "order": "r",
    "md5sum": "0e769317b90ac30d6e09486d61fefa26",
    "name": "Mini Orca (Small)",
    "filename": "orca-mini-3b-gguf2-q4_0.gguf",
    "filesize": "1979946720",
    "requires": "2.5.0",
    "ramrequired": "4",
    "parameters": "3 billion",
    "quant": "q4_0",
    "type": "OpenLLaMa",
    "description": "<strong>Small version of new model with novel dataset</strong><br><ul><li>Very fast responses</li><li>Instruction based</li><li>Explain tuned datasets</li><li>Orca Research Paper dataset construction approaches</li><li>Cannot be used commercially</li></ul>",
    "url": "https://gpt4all.io/models/gguf/orca-mini-3b-gguf2-q4_0.gguf",
    "promptTemplate": "### User:\n%1\n\n### Response:\n",
    "systemPrompt": "### System:\nYou are an AI assistant that follows instruction extremely well. Help as much as you can.\n\n"
  },
  {
    "order": "s",
    "md5sum": "c232f17e09bca4b7ee0b5b1f4107c01e",
    "disableGUI": "true",
    "name": "Replit",
    "filename": "replit-code-v1_5-3b-newbpe-q4_0.gguf",
    "filesize": "1953055104",
    "requires": "2.6.0",
    "ramrequired": "4",
    "parameters": "3 billion",
    "quant": "q4_0",
    "type": "Replit",
    "systemPrompt": "",
    "promptTemplate": "%1",
    "description": "<strong>Trained on subset of the Stack</strong><br><ul><li>Code completion based<li>Licensed for commercial use<li>WARNING: Not available for chat GUI</ul>",
    "url": "https://gpt4all.io/models/gguf/replit-code-v1_5-3b-newbpe-q4_0.gguf"
  },
  {
    "order": "t",
    "md5sum": "70841751ccd95526d3dcfa829e11cd4c",
    "disableGUI": "true",
    "name": "Starcoder",
    "filename": "starcoder-newbpe-q4_0.gguf",
    "filesize": "8987411904",
    "requires": "2.6.0",
    "ramrequired": "4",
    "parameters": "7 billion",
    "quant": "q4_0",
    "type": "Starcoder",
    "systemPrompt": "",
    "promptTemplate": "%1",
    "description": "<strong>Trained on subset of the Stack</strong><br><ul><li>Code completion based<li>WARNING: Not available for chat GUI</ul>",
    "url": "https://gpt4all.io/models/gguf/starcoder-newbpe-q4_0.gguf"
  },
  {
    "order": "u",
    "md5sum": "e973dd26f0ffa6e46783feaea8f08c83",
    "disableGUI": "true",
    "name": "Rift coder",
    "filename": "rift-coder-v0-7b-q4_0.gguf",
    "filesize": "3825903776",
    "requires": "2.5.0",
    "ramrequired": "8",
    "parameters": "7 billion",
    "quant": "q4_0",
    "type": "LLaMA",
    "systemPrompt": "",
    "promptTemplate": "%1",
    "description": "<strong>Trained on collection of Python and TypeScript</strong><br><ul><li>Code completion based<li>WARNING: Not available for chat GUI</li>",
    "url": "https://gpt4all.io/models/gguf/rift-coder-v0-7b-q4_0.gguf"
  },
  {
    "order": "v",
    "md5sum": "e479e6f38b59afc51a470d1953a6bfc7",
    "disableGUI": "true",
    "name": "SBert",
    "filename": "all-MiniLM-L6-v2-f16.gguf",
    "filesize": "45887744",
    "requires": "2.5.0",
    "removedIn": "2.7.4",
    "ramrequired": "1",
    "parameters": "40 million",
    "quant": "f16",
    "type": "Bert",
    "embeddingModel": true,
    "systemPrompt": "",
    "description": "<strong>LocalDocs text embeddings model</strong><br><ul><li>For use with LocalDocs feature<li>Used for retrieval augmented generation (RAG)",
    "url": "https://gpt4all.io/models/gguf/all-MiniLM-L6-v2-f16.gguf"
  },
  {
    "order": "w",
    "md5sum": "dd90e2cb7f8e9316ac3796cece9883b5",
    "name": "SBert",
    "filename": "all-MiniLM-L6-v2.gguf2.f16.gguf",
    "filesize": "45949216",
    "requires": "2.7.4",
    "removedIn": "3.0.0",
    "ramrequired": "1",
    "parameters": "40 million",
    "quant": "f16",
    "type": "Bert",
    "embeddingModel": true,
    "description": "<strong>LocalDocs text embeddings model</strong><br><ul><li>For use with LocalDocs feature<li>Used for retrieval augmented generation (RAG)",
    "url": "https://gpt4all.io/models/gguf/all-MiniLM-L6-v2.gguf2.f16.gguf"
  },
  {
    "order": "x",
    "md5sum": "919de4dd6f25351bcb0223790db1932d",
    "name": "EM German Mistral",
    "filename": "em_german_mistral_v01.Q4_0.gguf",
    "filesize": "4108916352",
    "requires": "2.5.0",
    "ramrequired": "8",
    "parameters": "7 billion",
    "quant": "q4_0",
    "type": "Mistral",
    "description": "<strong>Mistral-based model for German-language applications</strong><br><ul><li>Fast responses</li><li>Chat based model</li><li>Trained by ellamind<li>Finetuned on German instruction and chat data</a><li>Licensed for commercial use</ul>",
    "url": "https://huggingface.co/TheBloke/em_german_mistral_v01-GGUF/resolve/main/em_german_mistral_v01.Q4_0.gguf",
    "promptTemplate": "USER: %1 ASSISTANT: ",
    "systemPrompt": "Du bist ein hilfreicher Assistent. "
  },
  {
    "order": "y",
    "md5sum": "60ea031126f82db8ddbbfecc668315d2",
    "disableGUI": "true",
    "name": "Nomic Embed Text v1",
    "filename": "nomic-embed-text-v1.f16.gguf",
    "filesize": "274290560",
    "requires": "2.7.4",
    "ramrequired": "1",
    "parameters": "137 million",
    "quant": "f16",
    "type": "Bert",
    "embeddingModel": true,
    "systemPrompt": "",
    "description": "nomic-embed-text-v1",
    "url": "https://gpt4all.io/models/gguf/nomic-embed-text-v1.f16.gguf"
  },
  {
    "order": "z",
    "md5sum": "a5401e7f7e46ed9fcaed5b60a281d547",
    "disableGUI": "true",
    "name": "Nomic Embed Text v1.5",
    "filename": "nomic-embed-text-v1.5.f16.gguf",
    "filesize": "274290560",
    "requires": "2.7.4",
    "ramrequired": "1",
    "parameters": "137 million",
    "quant": "f16",
    "type": "Bert",
    "embeddingModel": true,
    "systemPrompt": "",
    "description": "nomic-embed-text-v1.5",
    "url": "https://gpt4all.io/models/gguf/nomic-embed-text-v1.5.f16.gguf"
  },
  {
    "order": "zzz",
    "md5sum": "a8c5a783105f87a481543d4ed7d7586d",
    "name": "Qwen2-1.5B-Instruct",
    "filename": "qwen2-1_5b-instruct-q4_0.gguf",
    "filesize": "937532800",
    "requires": "3.0",
    "ramrequired": "4",
    "parameters": "1.5 billion",
    "quant": "q4_0",
    "type": "qwen2",
    "description": "<ul><li>Very fast responses</li><li>Instruction based model</li><li>Usage of LocalDocs (RAG): Highly recommended</li><li>Supports context length of up to 32768</li><li>Trained and finetuned by Qwen (Alibaba Cloud)</li><li>License: <a href=\"https://www.apache.org/licenses/LICENSE-2.0.html/\">Apache 2.0</a></li></ul>",
    "url": "https://huggingface.co/Qwen/Qwen2-1.5B-Instruct-GGUF/resolve/main/qwen2-1_5b-instruct-q4_0.gguf",
    "promptTemplate": "<|im_start|>user\n%1<|im_end|>\n<|im_start|>assistant\n%2<|im_end|>",
    "systemPrompt": "<|im_start|>system\nBelow is an instruction that describes a task. Write a response that appropriately completes the request.<|im_end|>\n"
  }
]
